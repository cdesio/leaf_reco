{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/storage/yw18581/data/'\n",
    "data_folder = os.path.join(data_dir, 'train_validation_test')\n",
    "clean_dir = os.path.join(data_folder, 'clean_300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_X(arr, reshape = None):\n",
    "    x_cut = arr[:,960:1300,600:]\n",
    "    if reshape:\n",
    "        if len(x_cut.shape)>3:\n",
    "            x_cut = x_cut[...,0]\n",
    "            x_cut_out = x_cut.reshape(x_cut.shape[0],x_cut.shape[1]*x_cut.shape[2])\n",
    "    else:\n",
    "        x_cut_out = x_cut\n",
    "    return x_cut_out\n",
    "\n",
    "def reshape_RF(arr):\n",
    "    arr_RF = arr.reshape((arr.shape[0], arr.shape[1]*arr.shape[2]))\n",
    "    return arr_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_reshape(arr):\n",
    "    arr_cut = cut_X(arr)\n",
    "    arr_RF = reshape_RF(arr_cut)\n",
    "    return arr_RF\n",
    "\n",
    "def load_data(folder, dist):\n",
    "    X = np.load(os.path.join(folder, \"Xy_{}mm_clean_300.npz\".format(dist)))[\"y\"]\n",
    "    y = np.load(os.path.join(folder, \"Xy_{}mm_clean_300.npz\".format(dist)))[\"dist\"]\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1mm, y_1mm = load_data(clean_dir, 1)\n",
    "X_2mm, y_2mm = load_data(clean_dir, 2)\n",
    "X_3mm, y_3mm = load_data(clean_dir, 3)\n",
    "X_4mm, y_4mm = load_data(clean_dir, 4)\n",
    "X_10mm, y_10mm = load_data(clean_dir, 10)\n",
    "X_15mm, y_15mm = load_data(clean_dir, 15)\n",
    "X_20mm, y_20mm = load_data(clean_dir, 20)\n",
    "X_25mm, y_25mm = load_data(clean_dir, 25)\n",
    "X_30mm, y_30mm = load_data(clean_dir, 30)\n",
    "X_35mm, y_35mm = load_data(clean_dir, 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1mm_RF = cut_reshape(X_1mm)\n",
    "X_2mm_RF = cut_reshape(X_2mm)\n",
    "X_3mm_RF = cut_reshape(X_3mm)\n",
    "X_4mm_RF = cut_reshape(X_4mm)\n",
    "X_10mm_RF = cut_reshape(X_10mm)\n",
    "X_15mm_RF = cut_reshape(X_15mm)\n",
    "X_20mm_RF = cut_reshape(X_20mm)\n",
    "X_25mm_RF = cut_reshape(X_25mm)\n",
    "X_30mm_RF = cut_reshape(X_30mm)\n",
    "X_35mm_RF = cut_reshape(X_35mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_splitted_gt(pos):\n",
    "    Xy = np.load(os.path.join(clean_dir,\"Xy_\"+pos+\"_clean_300.npz\"))\n",
    "    X = Xy[\"y\"]\n",
    "    y = Xy[\"dist\"]\n",
    "    X_RF = cut_reshape(X)\n",
    "    indices = np.load(os.path.join(clean_dir,\"RF_train_test_indices_80_20_\"+pos+\"_clean.npz\"))\n",
    "    training_indices = indices[\"train\"]\n",
    "    test_indices = indices[\"test\"]\n",
    "    X_RF_train = X_RF[training_indices]\n",
    "    y_train = y[training_indices]\n",
    "    X_RF_test = X_RF[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    return X_RF_train, y_train, X_RF_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1mm_cl_RF_train, y_1mm_cl_train, X_1mm_cl_RF_test, y_1mm_cl_test  = import_splitted_gt(\"1mm\")\n",
    "X_2mm_cl_RF_train, y_2mm_cl_train, X_2mm_cl_RF_test, y_2mm_cl_test = import_splitted_gt(\"2mm\")\n",
    "X_3mm_cl_RF_train, y_3mm_cl_train, X_3mm_cl_RF_test, y_3mm_cl_test = import_splitted_gt(\"3mm\")\n",
    "X_4mm_cl_RF_train, y_4mm_cl_train, X_4mm_cl_RF_test, y_4mm_cl_test= import_splitted_gt(\"4mm\")\n",
    "X_10mm_cl_RF_train, y_10mm_cl_train, X_10mm_cl_RF_test, y_10mm_cl_test = import_splitted_gt(\"10mm\")\n",
    "X_15mm_cl_RF_train, y_15mm_cl_train, X_15mm_cl_RF_test, y_15mm_cl_test = import_splitted_gt(\"15mm\")\n",
    "X_20mm_cl_RF_train, y_20mm_cl_train, X_20mm_cl_RF_test, y_20mm_cl_test = import_splitted_gt(\"20mm\")\n",
    "X_25mm_cl_RF_train, y_25mm_cl_train, X_25mm_cl_RF_test, y_25mm_cl_test = import_splitted_gt(\"25mm\")\n",
    "X_30mm_cl_RF_train, y_30mm_cl_train, X_30mm_cl_RF_test, y_30mm_cl_test = import_splitted_gt(\"30mm\")\n",
    "X_35mm_cl_RF_train, y_35mm_cl_train, X_35mm_cl_RF_test, y_35mm_cl_test = import_splitted_gt(\"35mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cl_RF = np.vstack([X_2mm_cl_RF_train, X_4mm_cl_RF_train, X_10mm_cl_RF_train, X_25mm_cl_RF_train])\n",
    "y_train_cl_RF = np.hstack([y_2mm_cl_train, y_4mm_cl_train, y_10mm_cl_train, y_25mm_cl_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(max_depth=8, n_estimators=30, random_state=42, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 30\n",
      "building tree 3 of 30\n",
      "building tree 4 of 30\n",
      "building tree 5 of 30\n",
      "building tree 6 of 30\n",
      "building tree 7 of 30\n",
      "building tree 8 of 30\n",
      "building tree 9 of 30\n",
      "building tree 10 of 30\n",
      "building tree 11 of 30\n",
      "building tree 12 of 30\n",
      "building tree 13 of 30\n",
      "building tree 14 of 30\n",
      "building tree 15 of 30\n",
      "building tree 16 of 30\n",
      "building tree 17 of 30\n",
      "building tree 18 of 30\n",
      "building tree 19 of 30\n",
      "building tree 20 of 30\n",
      "building tree 21 of 30\n",
      "building tree 22 of 30\n",
      "building tree 23 of 30\n",
      "building tree 24 of 30\n",
      "building tree 25 of 30\n",
      "building tree 26 of 30\n",
      "building tree 27 of 30\n",
      "building tree 28 of 30\n",
      "building tree 29 of 30\n",
      "building tree 30 of 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=8,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=None,\n",
       "           oob_score=False, random_state=42, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train_cl_RF, y_train_cl_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cl_RF = np.vstack([X_2mm_cl_RF_test, X_4mm_cl_RF_test, X_10mm_cl_RF_test, X_25mm_cl_RF_test])\n",
    "y_test_cl_RF = np.hstack([y_2mm_cl_test, y_4mm_cl_test, y_10mm_cl_test, y_25mm_cl_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "preds_gt = rf.predict(X_test_cl_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0010972222222222225"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(preds_gt, y_test_cl_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_splitted_UNet(pos):\n",
    "    Xy = np.load(os.path.join(clean_dir,\"Xy_\"+pos+\"_clean_300_predicted_UNet.npz\"))\n",
    "    X = Xy[\"y\"]\n",
    "    y = Xy[\"dist\"]\n",
    "    X_RF = cut_reshape(X)\n",
    "    indices = np.load(os.path.join(clean_dir,\"RF_train_test_indices_80_20_\"+pos+\"_clean.npz\"))\n",
    "    training_indices = indices[\"train\"]\n",
    "    test_indices = indices[\"test\"]\n",
    "    X_RF_train = X_RF[training_indices]\n",
    "    y_train = y[training_indices]\n",
    "    X_RF_test = X_RF[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    return X_RF_train, y_train, X_RF_test, y_test\n",
    "\n",
    "\n",
    "#X_1mm_cl_UNet_RF_train, y_1mm_cl_UNet_train, X_1mm_cl_UNet_RF_test, y_1mm_cl_UNet_test  = import_splitted_UNet(\"1mm\")\n",
    "X_2mm_cl_UNet_RF_train, y_2mm_cl_UNet_train, X_2mm_cl_UNet_RF_test, y_2mm_cl_UNet_test  = import_splitted_UNet(\"2mm\")\n",
    "#X_3mm_cl_UNet_RF_train, y_3mm_cl_UNet_train, X_3mm_cl_UNet_RF_test, y_3mm_cl_UNet_test  = import_splitted_UNet(\"3mm\")\n",
    "X_4mm_cl_UNet_RF_train, y_4mm_cl_UNet_train, X_4mm_cl_UNet_RF_test, y_4mm_cl_UNet_test  = import_splitted_UNet(\"4mm\")\n",
    "X_10mm_cl_UNet_RF_train, y_10mm_cl_UNet_train, X_10mm_cl_UNet_RF_test, y_10mm_cl_UNet_test  = import_splitted_UNet(\"10mm\")\n",
    "#X_15mm_cl_UNet_RF_train, y_15mm_cl_UNet_train, X_15mm_cl_UNet_RF_test, y_15mm_cl_UNet_test  = import_splitted_UNet(\"15mm\")\n",
    "#X_20mm_cl_UNet_RF_train, y_20mm_cl_UNet_train, X_20mm_cl_UNet_RF_test, y_20mm_cl_UNet_test  = import_splitted_UNet(\"20mm\")\n",
    "X_25mm_cl_UNet_RF_train, y_25mm_cl_UNet_train, X_25mm_cl_UNet_RF_test, y_25mm_cl_UNet_test  = import_splitted_UNet(\"25mm\")\n",
    "#X_30mm_cl_UNet_RF_train, y_30mm_cl_UNet_train, X_30mm_cl_UNet_RF_test, y_30mm_cl_UNet_test  = import_splitted_UNet(\"30mm\")\n",
    "#X_35mm_cl_UNet_RF_train, y_35mm_cl_UNet_train, X_35mm_cl_UNet_RF_test, y_35mm_cl_UNet_test  = import_splitted_UNet(\"35mm\")\\\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cl_RF_UNet = np.vstack([X_2mm_cl_UNet_RF_test, X_4mm_cl_UNet_RF_test, X_10mm_cl_UNet_RF_test, X_25mm_cl_UNet_RF_test])\n",
    "y_test_cl_RF_UNet = np.hstack([y_2mm_cl_UNet_test, y_4mm_cl_UNet_test, y_10mm_cl_UNet_test, y_25mm_cl_UNet_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.006962962962962971"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_unet = rf.predict(X_test_cl_RF_UNet)\n",
    "\n",
    "\n",
    "mean_squared_error(preds_unet, y_test_cl_RF_UNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.6       ,  2.        ,  2.        ,  2.        ,  2.        ,\n",
       "        2.        ,  2.        ,  2.        ,  2.        ,  2.        ,\n",
       "        2.        ,  2.        ,  2.        ,  2.33333333,  2.        ,\n",
       "        2.        ,  2.        ,  2.        ,  2.06666667,  2.        ,\n",
       "        2.        ,  2.        ,  2.46666667,  2.06666667,  2.        ,\n",
       "        2.        ,  2.        ,  2.        ,  2.        ,  2.13333333,\n",
       "        2.        ,  2.        ,  2.        ,  2.33333333,  2.        ,\n",
       "        2.13333333,  2.13333333,  2.        ,  2.        ,  2.        ,\n",
       "        2.        ,  2.        ,  2.        ,  2.        ,  2.        ,\n",
       "        2.        ,  2.        ,  2.        ,  2.        ,  2.        ,\n",
       "        2.        ,  2.        ,  2.2       ,  2.        ,  2.        ,\n",
       "        2.06666667,  2.06666667,  2.        ,  2.        ,  2.        ,\n",
       "        4.        ,  4.2       ,  4.        ,  4.        ,  4.        ,\n",
       "        4.2       ,  4.        ,  4.        ,  4.        ,  4.4       ,\n",
       "        4.2       ,  4.        ,  4.        ,  4.4       ,  4.        ,\n",
       "        4.        ,  4.        ,  4.        ,  4.        ,  4.        ,\n",
       "        4.        ,  4.2       ,  4.        ,  4.        ,  4.        ,\n",
       "        4.        ,  4.        ,  4.        ,  4.        ,  4.        ,\n",
       "        4.2       ,  4.        ,  4.        ,  4.2       ,  4.        ,\n",
       "        4.        ,  4.        ,  4.        ,  4.        ,  4.        ,\n",
       "        4.        ,  4.        ,  4.        ,  4.        ,  4.        ,\n",
       "        4.4       ,  4.        ,  4.        ,  4.        ,  4.        ,\n",
       "        4.        ,  4.        ,  4.        ,  4.2       ,  4.        ,\n",
       "        4.        ,  4.        ,  4.        ,  4.        ,  4.        ,\n",
       "       10.        , 10.        , 10.        , 10.        , 10.        ,\n",
       "       10.        , 10.        , 10.        , 10.        , 10.        ,\n",
       "       10.        , 10.        , 10.        , 10.        , 10.        ,\n",
       "       10.        , 10.        , 10.        , 10.        , 10.        ,\n",
       "       10.        , 10.        , 10.        , 10.        , 10.        ,\n",
       "       10.        , 10.        , 10.        , 10.        , 10.        ,\n",
       "       10.        , 10.        , 10.        , 10.        , 10.        ,\n",
       "       10.        , 10.        , 10.        , 10.        , 10.        ,\n",
       "       10.        , 10.        , 10.        , 10.        , 10.        ,\n",
       "       10.        , 10.        , 10.        , 10.        , 10.        ,\n",
       "       10.        , 10.        , 10.        , 10.        , 10.        ,\n",
       "       10.        , 10.        , 10.        , 10.        , 10.        ,\n",
       "       25.        , 25.        , 25.        , 25.        , 25.        ,\n",
       "       25.        , 25.        , 25.        , 25.        , 25.        ,\n",
       "       25.        , 25.        , 25.        , 25.        , 25.        ,\n",
       "       25.        , 25.        , 25.        , 25.        , 25.        ,\n",
       "       25.        , 25.        , 25.        , 25.        , 25.        ,\n",
       "       25.        , 25.        , 25.        , 25.        , 25.        ,\n",
       "       25.        , 25.        , 25.        , 25.        , 25.        ,\n",
       "       25.        , 25.        , 25.        , 25.        , 25.        ,\n",
       "       25.        , 25.        , 25.        , 25.        , 25.        ,\n",
       "       25.        , 25.        , 25.        , 25.        , 25.        ,\n",
       "       25.        , 25.        , 25.        , 25.        , 25.        ,\n",
       "       25.        , 25.        , 25.        , 25.        , 25.        ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_unet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing function to prepare data and  run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_FOLDER_PATH = os.path.join(data_dir, 'trained_models')\n",
    "TASK_NAME = 'UNet_retrain_new_data_clean_300'\n",
    "TASK_FOLDER_PATH = os.path.join(CHECKPOINT_FOLDER_PATH, TASK_NAME)\n",
    "if not os.path.exists(TASK_FOLDER_PATH):\n",
    "    os.makedirs(TASK_FOLDER_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_test_validation_metadata_arguments_dt import train_validation_test\n",
    "\n",
    "def import_and_split(dist):\n",
    "    with open(os.path.join(clean_dir, \"Xy_{}mm_clean_300.npz\".format(dist))) as Xy:\n",
    "        X = Xy[\"x\"]\n",
    "        y = Xy[\"y\"]\n",
    "        _, test_indices, train_indices, val_indices = train_validation_test(X)\n",
    "        Xy.close()\n",
    "    return X, y, train_indices, val_indices, test_indices\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_validation_dataset(dist_list):\n",
    "    for d in dist_list:\n",
    "        print(\"loading {}mm\".format(d))\n",
    "        X_d, y_d, train_indices_d, val_indices_d, test_indices_d = import_and_split(d)\n",
    "        print(\"saving indices for {}mm\".format(d))\n",
    "        np.savez_compressed(os.path.join(TASK_FOLDER_PATH, \"train_val_test_indices_{}mm.npz\".format(d)), \n",
    "                            train=train_indices_d, val = val_indices_d, test = test_indices_d)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 1mm\n",
      "saving indices for 1mm\n",
      "loading 2mm\n",
      "saving indices for 2mm\n",
      "loading 4mm\n",
      "saving indices for 4mm\n",
      "loading 10mm\n",
      "saving indices for 10mm\n",
      "loading 25mm\n",
      "saving indices for 25mm\n",
      "loading 35mm\n",
      "saving indices for 35mm\n",
      "creating train, validation, test dataset\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f451c80ec38e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mXtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXte\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_train_validation_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m35\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-777130e661a5>\u001b[0m in \u001b[0;36mbuild_train_validation_dataset\u001b[0;34m(dist_list)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_d_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"creating train, validation, test dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/fluffy-bunnies/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Xtr, Xv, Xte, ytr, yv, yte = build_train_validation_dataset([1,2, 4, 10, 25, 35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 1400, 1400, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 1400, 1400, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
