{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 14 20:10:20 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 410.79       Driver Version: 410.79       CUDA Version: 10.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN Xp            Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 34%   48C    P0    72W / 250W |      0MiB / 12195MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.losses import categorical_crossentropy, mse\n",
    "from keras.optimizers import Adadelta, Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, ymin_loss=None, ymax_loss=None, ymin_acc=None, ymax_acc=None):\n",
    "    ymin_loss=np.min(history.history['loss'])\n",
    "    ymax_loss=np.max(history.history['loss'])\n",
    "    f1 = plt.figure()\n",
    "    plt.plot(history.history['loss'],label='training')\n",
    "    plt.plot(history.history['val_loss'],label='validation')\n",
    "    plt.ylim(ymin_loss,ymax_loss)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "    if 'acc' in history.history:\n",
    "        ymin_acc=np.min(history.history['acc'])\n",
    "        ymax_acc=np.max(history.history['acc'])\n",
    "        f2 = plt.figure()\n",
    "        plt.plot(history.history['acc'],label='training')\n",
    "        plt.plot(history.history['val_acc'],label='validation')\n",
    "        plt.ylim(ymin_acc,ymax_acc)\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/storage/yw18581/data/'\n",
    "data_folder = os.path.join(data_dir, 'train_validation_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(os.path.join(data_folder, 'Xy_train_dist.npz'))[\"y\"]\n",
    "y_train = np.load(os.path.join(data_folder, 'Xy_train_dist.npz'))[\"dist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = np.load(os.path.join(data_folder,'Xy_val_dist.npz'))[\"y\"]\n",
    "y_val = np.load(os.path.join(data_folder, 'Xy_val_dist.npz'))[\"dist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(os.path.join(data_folder, 'Xy_test_dist.npz'))[\"y\"]\n",
    "y_test = np.load(os.path.join(data_folder, 'Xy_test_dist.npz'))[\"dist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = np.load(os.path.join(data_dir, 'trained_models/UNet_training_generator_1500epochs/Xy_test_predicted_UNet.npz'))['y']\n",
    "y_pred = np.load(os.path.join(data_dir, 'trained_models/UNet_training_generator_1500epochs/Xy_test_predicted_UNet.npz'))['dist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_X(arr):\n",
    "    x_cut = arr[:,960:1300,600:]\n",
    "    if len(x_cut.shape)>3:\n",
    "        x_cut = x_cut[...,0]\n",
    "    x_cut_out = x_cut.reshape(x_cut.shape[0],x_cut.shape[1]*x_cut.shape[2])\n",
    "    return x_cut_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cut = cut_X(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_cut = cut_X(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cut = cut_X(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_cut = cut_X(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 272000)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               139264512 \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 4104      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 139,268,625\n",
      "Trainable params: 139,268,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(input_shape):\n",
    "    input_layer = Input(shape=input_shape,name='input')\n",
    "    x = Dense(512, activation ='sigmoid')(input_layer)\n",
    "    #x = Dense(128, activation ='sigmoid')(x)\n",
    "    #x = Dense(64, activation ='sigmoid')(x)\n",
    "    #x = Dense(16, activation ='sigmoid')(x)\n",
    "    x = Dense(8, activation ='sigmoid')(x)\n",
    "    prediction = Dense(1, activation='linear')(x)\n",
    "    model = Model(inputs = input_layer, outputs = prediction)\n",
    "    return model\n",
    "\n",
    "model = create_model(input_shape=(X_train_cut.shape[1],))\n",
    "model.compile(loss='mse',\n",
    "              optimizer=Adadelta())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 768 samples, validate on 192 samples\n",
      "Epoch 1/200\n",
      "768/768 [==============================] - 13s 17ms/step - loss: 151.3619 - val_loss: 155.6736\n",
      "Epoch 2/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 145.1869 - val_loss: 149.8392\n",
      "Epoch 3/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 139.8409 - val_loss: 144.3830\n",
      "Epoch 4/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 134.8790 - val_loss: 139.3131\n",
      "Epoch 5/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 130.2505 - val_loss: 134.5559\n",
      "Epoch 6/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 125.9388 - val_loss: 130.1351\n",
      "Epoch 7/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 121.9594 - val_loss: 126.0472\n",
      "Epoch 8/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 118.2810 - val_loss: 122.2416\n",
      "Epoch 9/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 114.8746 - val_loss: 118.7101\n",
      "Epoch 10/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 111.6998 - val_loss: 115.4132\n",
      "Epoch 11/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 108.7821 - val_loss: 112.3811\n",
      "Epoch 12/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 106.1078 - val_loss: 109.5878\n",
      "Epoch 13/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 103.6246 - val_loss: 106.9780\n",
      "Epoch 14/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 101.0517 - val_loss: 99.6125\n",
      "Epoch 15/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 88.7692 - val_loss: 86.4801\n",
      "Epoch 16/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 83.1268 - val_loss: 83.3635\n",
      "Epoch 17/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 81.8996 - val_loss: 82.4831\n",
      "Epoch 18/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 81.5894 - val_loss: 82.1742\n",
      "Epoch 19/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 81.4569 - val_loss: 81.0549\n",
      "Epoch 20/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 82.4179 - val_loss: 81.4167\n",
      "Epoch 21/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 78.5330 - val_loss: 75.3631\n",
      "Epoch 22/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 73.0680 - val_loss: 72.9566\n",
      "Epoch 23/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 67.8196 - val_loss: 67.4614\n",
      "Epoch 24/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 64.8789 - val_loss: 62.5180\n",
      "Epoch 25/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 62.2909 - val_loss: 61.0599\n",
      "Epoch 26/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 59.6431 - val_loss: 58.0762\n",
      "Epoch 27/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 58.4634 - val_loss: 58.7028\n",
      "Epoch 28/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 55.4773 - val_loss: 53.1013\n",
      "Epoch 29/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 53.1106 - val_loss: 53.8109\n",
      "Epoch 30/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 51.2272 - val_loss: 50.9296\n",
      "Epoch 31/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 48.4670 - val_loss: 47.8158\n",
      "Epoch 32/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 47.1195 - val_loss: 45.4719\n",
      "Epoch 33/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 44.5937 - val_loss: 43.5013\n",
      "Epoch 34/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 42.7987 - val_loss: 41.3445\n",
      "Epoch 35/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 41.0779 - val_loss: 43.2191\n",
      "Epoch 36/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 39.4683 - val_loss: 38.8201\n",
      "Epoch 37/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 38.1902 - val_loss: 38.6656\n",
      "Epoch 38/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 36.3563 - val_loss: 35.5057\n",
      "Epoch 39/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 35.1418 - val_loss: 34.1279\n",
      "Epoch 40/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 33.6799 - val_loss: 32.9438\n",
      "Epoch 41/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 32.5506 - val_loss: 32.8276\n",
      "Epoch 42/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 31.4793 - val_loss: 30.7516\n",
      "Epoch 43/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 30.3220 - val_loss: 30.0500\n",
      "Epoch 44/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 29.5032 - val_loss: 29.6175\n",
      "Epoch 45/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 28.3002 - val_loss: 27.7198\n",
      "Epoch 46/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 27.4585 - val_loss: 27.1118\n",
      "Epoch 47/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 26.5096 - val_loss: 26.0057\n",
      "Epoch 48/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 25.7068 - val_loss: 25.6782\n",
      "Epoch 49/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 24.7951 - val_loss: 24.3803\n",
      "Epoch 50/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 24.0881 - val_loss: 23.6287\n",
      "Epoch 51/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 23.3125 - val_loss: 22.9416\n",
      "Epoch 52/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 22.6570 - val_loss: 22.3035\n",
      "Epoch 53/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 21.8947 - val_loss: 21.8244\n",
      "Epoch 54/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 21.3237 - val_loss: 21.1265\n",
      "Epoch 55/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 20.5834 - val_loss: 20.5297\n",
      "Epoch 56/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 20.0107 - val_loss: 19.8765\n",
      "Epoch 57/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 19.5339 - val_loss: 19.1699\n",
      "Epoch 58/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 18.9230 - val_loss: 18.7732\n",
      "Epoch 59/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 18.3598 - val_loss: 18.2018\n",
      "Epoch 60/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 17.7735 - val_loss: 17.9535\n",
      "Epoch 61/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 17.3314 - val_loss: 17.2917\n",
      "Epoch 62/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 16.8369 - val_loss: 16.7735\n",
      "Epoch 63/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 16.5096 - val_loss: 17.7549\n",
      "Epoch 64/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 16.0833 - val_loss: 15.9291\n",
      "Epoch 65/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 15.5632 - val_loss: 15.6752\n",
      "Epoch 66/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 15.0364 - val_loss: 15.0874\n",
      "Epoch 67/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 14.6464 - val_loss: 14.5847\n",
      "Epoch 68/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 14.3090 - val_loss: 14.3764\n",
      "Epoch 69/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 13.9258 - val_loss: 14.0709\n",
      "Epoch 70/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 13.5648 - val_loss: 13.5106\n",
      "Epoch 71/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 13.2706 - val_loss: 13.0918\n",
      "Epoch 72/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 12.8538 - val_loss: 12.8694\n",
      "Epoch 73/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 12.5506 - val_loss: 12.4585\n",
      "Epoch 74/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 12.2208 - val_loss: 12.2071\n",
      "Epoch 75/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 11.9654 - val_loss: 11.8547\n",
      "Epoch 76/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 11.5957 - val_loss: 11.5948\n",
      "Epoch 77/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 11.4691 - val_loss: 11.2784\n",
      "Epoch 78/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 11.0658 - val_loss: 10.9649\n",
      "Epoch 79/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 10.7786 - val_loss: 10.7489\n",
      "Epoch 80/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 10.5143 - val_loss: 10.5997\n",
      "Epoch 81/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 10.3653 - val_loss: 10.6706\n",
      "Epoch 82/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 10.0056 - val_loss: 10.0333\n",
      "Epoch 83/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 9.7237 - val_loss: 9.8160\n",
      "Epoch 84/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 9.5077 - val_loss: 9.4840\n",
      "Epoch 85/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 9.2667 - val_loss: 9.0924\n",
      "Epoch 86/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 8.8793 - val_loss: 9.2295\n",
      "Epoch 87/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 8.2682 - val_loss: 7.7788\n",
      "Epoch 88/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 7.6149 - val_loss: 7.5707\n",
      "Epoch 89/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 7.2761 - val_loss: 7.9451\n",
      "Epoch 90/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 6.6030 - val_loss: 5.5975\n",
      "Epoch 91/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 5.6984 - val_loss: 5.6944\n",
      "Epoch 92/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 5.2914 - val_loss: 4.5060\n",
      "Epoch 93/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 4.9129 - val_loss: 5.8388\n",
      "Epoch 94/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 4.2668 - val_loss: 4.9833\n",
      "Epoch 95/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 3.7628 - val_loss: 3.9100\n",
      "Epoch 96/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 3.4376 - val_loss: 3.8738\n",
      "Epoch 97/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 3.0437 - val_loss: 3.8484\n",
      "Epoch 98/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 2.7023 - val_loss: 2.3733\n",
      "Epoch 99/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 2.1743 - val_loss: 2.2326\n",
      "Epoch 100/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 2.0059 - val_loss: 2.2945\n",
      "Epoch 101/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 1.7910 - val_loss: 1.7056\n",
      "Epoch 102/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 1.5796 - val_loss: 1.5744\n",
      "Epoch 103/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 1.4024 - val_loss: 1.3588\n",
      "Epoch 104/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 1.1797 - val_loss: 1.1215\n",
      "Epoch 105/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 1.1073 - val_loss: 0.9735\n",
      "Epoch 106/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.8926 - val_loss: 0.8370\n",
      "Epoch 107/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 0.8024 - val_loss: 0.9160\n",
      "Epoch 108/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.7654 - val_loss: 0.7033\n",
      "Epoch 109/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.6343 - val_loss: 0.5473\n",
      "Epoch 110/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.6022 - val_loss: 0.4689\n",
      "Epoch 111/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.4279 - val_loss: 0.4147\n",
      "Epoch 112/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.3890 - val_loss: 0.3501\n",
      "Epoch 113/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.3229 - val_loss: 0.3012\n",
      "Epoch 114/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.3157 - val_loss: 0.2624\n",
      "Epoch 115/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.2498 - val_loss: 0.7144\n",
      "Epoch 116/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.2072 - val_loss: 0.2007\n",
      "Epoch 117/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.2408 - val_loss: 0.2026\n",
      "Epoch 118/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.1689 - val_loss: 0.1973\n",
      "Epoch 119/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.1337 - val_loss: 0.1469\n",
      "Epoch 120/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.1376 - val_loss: 0.1614\n",
      "Epoch 121/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0822 - val_loss: 0.1250\n",
      "Epoch 122/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0912 - val_loss: 0.1122\n",
      "Epoch 123/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0648 - val_loss: 0.0544\n",
      "Epoch 124/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 0.0648 - val_loss: 0.0471\n",
      "Epoch 125/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0493 - val_loss: 0.0379\n",
      "Epoch 126/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0662 - val_loss: 0.7134\n",
      "Epoch 127/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 0.0973 - val_loss: 0.0280\n",
      "Epoch 128/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0263 - val_loss: 0.0296\n",
      "Epoch 129/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0480 - val_loss: 0.0245\n",
      "Epoch 130/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0548 - val_loss: 0.0251\n",
      "Epoch 131/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0017 - val_loss: 0.0309\n",
      "Epoch 132/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 0.0295 - val_loss: 0.0223\n",
      "Epoch 133/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 0.0392 - val_loss: 0.0208\n",
      "Epoch 134/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 0.0290 - val_loss: 0.0272\n",
      "Epoch 135/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 0.0025 - val_loss: 0.0302\n",
      "Epoch 136/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 0.0586 - val_loss: 0.0208\n",
      "Epoch 137/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0654 - val_loss: 0.0206\n",
      "Epoch 138/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0594 - val_loss: 0.0251\n",
      "Epoch 139/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0033 - val_loss: 0.0208\n",
      "Epoch 140/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0907 - val_loss: 0.0266\n",
      "Epoch 141/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0181 - val_loss: 0.0209\n",
      "Epoch 142/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0020 - val_loss: 0.2616\n",
      "Epoch 143/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0183 - val_loss: 0.0208\n",
      "Epoch 144/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 0.0671 - val_loss: 0.0210\n",
      "Epoch 145/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 2.9141e-04 - val_loss: 0.0393\n",
      "Epoch 146/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0431 - val_loss: 0.1762\n",
      "Epoch 147/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 0.0698 - val_loss: 0.0255\n",
      "Epoch 148/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0394 - val_loss: 0.0219\n",
      "Epoch 149/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0368 - val_loss: 0.0587\n",
      "Epoch 150/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 0.0559 - val_loss: 0.0258\n",
      "Epoch 151/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 0.0606 - val_loss: 0.0958\n",
      "Epoch 152/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 0.0635 - val_loss: 0.0223\n",
      "Epoch 153/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0037 - val_loss: 0.0324\n",
      "Epoch 154/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0361 - val_loss: 0.0250\n",
      "Epoch 155/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0458 - val_loss: 0.0223\n",
      "Epoch 156/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0237 - val_loss: 0.0350\n",
      "Epoch 157/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0281 - val_loss: 0.0208\n",
      "Epoch 158/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0285 - val_loss: 0.0209\n",
      "Epoch 159/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0236 - val_loss: 0.0208\n",
      "Epoch 160/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 0.0189 - val_loss: 0.0474\n",
      "Epoch 161/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0614 - val_loss: 0.0318\n",
      "Epoch 162/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0648 - val_loss: 0.2283\n",
      "Epoch 163/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 0.0698 - val_loss: 0.0213\n",
      "Epoch 164/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 0.0269 - val_loss: 0.0213\n",
      "Epoch 165/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 0.0516 - val_loss: 0.0976\n",
      "Epoch 166/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 0.0310 - val_loss: 0.0209\n",
      "Epoch 167/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0394 - val_loss: 0.1559\n",
      "Epoch 168/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 0.0083 - val_loss: 0.0222\n",
      "Epoch 169/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0487 - val_loss: 0.0208\n",
      "Epoch 170/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 0.0340 - val_loss: 0.0231\n",
      "Epoch 171/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0204 - val_loss: 0.0210\n",
      "Epoch 172/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 0.0565 - val_loss: 0.0206\n",
      "Epoch 173/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0401 - val_loss: 0.0209\n",
      "Epoch 174/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0131 - val_loss: 0.0209\n",
      "Epoch 175/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0138 - val_loss: 0.1121\n",
      "Epoch 176/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0462 - val_loss: 0.2046\n",
      "Epoch 177/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 0.0727 - val_loss: 0.0208\n",
      "Epoch 178/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0281 - val_loss: 0.0496\n",
      "Epoch 179/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0446 - val_loss: 0.0208\n",
      "Epoch 180/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0328 - val_loss: 0.1084\n",
      "Epoch 181/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0375 - val_loss: 0.0414\n",
      "Epoch 182/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0424 - val_loss: 0.0231\n",
      "Epoch 183/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 0.0254 - val_loss: 0.0563\n",
      "Epoch 184/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0437 - val_loss: 0.0208\n",
      "Epoch 185/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0346 - val_loss: 0.0208\n",
      "Epoch 186/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0113 - val_loss: 0.0206\n",
      "Epoch 187/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 0.0600 - val_loss: 0.0211\n",
      "Epoch 188/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0420 - val_loss: 0.0363\n",
      "Epoch 189/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0113 - val_loss: 0.1626\n",
      "Epoch 190/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0538 - val_loss: 0.0351\n",
      "Epoch 191/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 0.0558 - val_loss: 0.0208\n",
      "Epoch 192/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0224 - val_loss: 0.0233\n",
      "Epoch 193/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0837 - val_loss: 0.0209\n",
      "Epoch 194/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 0.0105 - val_loss: 0.0714\n",
      "Epoch 195/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0476 - val_loss: 0.0208\n",
      "Epoch 196/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 0.0346 - val_loss: 0.0267\n",
      "Epoch 197/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0186 - val_loss: 0.0223\n",
      "Epoch 198/200\n",
      "768/768 [==============================] - 4s 6ms/step - loss: 0.0508 - val_loss: 0.0208\n",
      "Epoch 199/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0338 - val_loss: 0.0208\n",
      "Epoch 200/200\n",
      "768/768 [==============================] - 4s 5ms/step - loss: 0.0174 - val_loss: 0.0307\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_cut, y_train, validation_data=(X_val_cut, y_val),\n",
    "                    epochs=200, verbose=True, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(data_dir,'trained_models','leaf_regression_shallow.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.ravel().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026234348483862153"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(y_test, preds.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  4, 10, 25])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_2 = y_test[y_test==2]\n",
    "t_test_4 = y_test[y_test==4]\n",
    "t_test_10 = y_test[y_test==10]\n",
    "t_test_25 = y_test[y_test==25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62,) (60,) (60,) (58,)\n"
     ]
    }
   ],
   "source": [
    "print(t_test_2.shape, t_test_4.shape, t_test_10.shape, t_test_25.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25.009554 , 10.109066 ,  2.00716  ,  4.1311665,  2.00716  ,\n",
       "       25.009554 ,  4.1311665, 25.009554 ,  4.1311665, 10.109066 ,\n",
       "       10.109066 ,  2.00716  ,  2.00716  , 10.109066 ,  2.00716  ,\n",
       "        2.00716  ,  4.1311665, 10.109066 , 10.109066 ,  4.1311665,\n",
       "        4.1311665, 10.109066 , 10.109066 ,  4.1311665,  2.00716  ,\n",
       "        2.005498 , 10.109066 ,  4.1311665,  4.1311665,  4.1311665,\n",
       "        4.1311665, 10.109066 , 10.109066 , 10.109066 ,  4.1311665,\n",
       "        4.1311665,  4.1311665,  2.0060782,  4.1311665, 10.109066 ,\n",
       "       25.009554 ,  2.00716  , 25.009554 ,  4.1311665, 25.009554 ,\n",
       "        4.1311665,  4.1311665,  2.00716  ,  2.00716  ,  2.00716  ,\n",
       "       10.109066 , 25.009554 ,  4.1311665,  2.00716  , 25.009554 ,\n",
       "        4.1311665, 25.009554 , 25.009554 , 25.009554 ,  4.1311665,\n",
       "        4.1311665,  2.00716  ,  2.00716  ,  2.00716  ,  2.00716  ,\n",
       "       25.009554 ,  2.00716  ,  4.1311665,  4.1311665,  4.1311665,\n",
       "        4.1311665,  2.00716  , 25.009554 ,  2.00716  ,  2.00716  ,\n",
       "        4.1311665,  2.00716  ,  2.00716  , 25.009554 , 10.109066 ,\n",
       "       25.009554 ,  2.00716  , 10.109066 ,  2.00716  ,  4.1311665,\n",
       "       25.009554 , 25.009554 ,  2.00716  , 25.009554 , 10.109066 ,\n",
       "        4.1311665,  4.1311665,  2.00716  ,  4.1311665, 25.009554 ,\n",
       "       10.109066 ,  4.1311665, 25.009554 ,  2.00716  ,  2.007151 ,\n",
       "        4.1311665,  2.00716  , 10.109066 ,  2.00716  , 10.109066 ,\n",
       "       10.109066 , 25.009554 , 25.009554 , 25.009554 , 25.009554 ,\n",
       "        4.1311665, 10.109066 ,  2.00716  , 25.009554 , 10.109066 ,\n",
       "       25.009554 ,  2.00716  ,  2.00716  , 10.109066 ,  2.00716  ,\n",
       "        4.1311665, 25.009554 , 25.009554 , 25.009554 ,  4.1311665,\n",
       "       25.009554 ,  4.1311665,  4.1311665, 10.109066 , 10.109066 ,\n",
       "        2.00716  , 25.009554 ,  4.1311665,  2.00716  , 25.009554 ,\n",
       "       10.109066 , 10.109066 ,  4.1311665,  4.1311665, 25.009554 ,\n",
       "       25.009554 , 10.109066 ,  4.1311107, 10.109066 , 10.109066 ,\n",
       "        4.1311665, 10.109066 , 10.109066 ,  4.1311665,  4.1311665,\n",
       "       25.009554 ,  4.1311665, 10.109066 ,  2.00716  , 25.009554 ,\n",
       "        4.1311665,  4.1311665,  2.00716  , 25.009554 ,  4.1311665,\n",
       "       25.009554 , 25.009554 , 25.009554 ,  2.00716  ,  2.00716  ,\n",
       "       10.109066 ,  2.00716  , 10.109066 , 10.109066 ,  2.00716  ,\n",
       "       10.109066 , 25.009554 ,  4.1311665,  2.00716  ,  2.00716  ,\n",
       "        4.1311665,  2.00716  , 25.009554 ,  2.00716  , 10.109066 ,\n",
       "       10.109066 , 10.109066 ,  2.00716  , 25.009554 ,  2.00716  ,\n",
       "       25.009554 ,  4.1311665, 10.109066 ,  4.1311665,  4.1311665,\n",
       "       10.109066 , 10.109066 ,  2.00716  , 10.109066 ,  4.1311665,\n",
       "        2.00716  ,  2.00716  , 25.009554 , 25.009554 ,  2.00716  ,\n",
       "       10.109066 , 25.009554 , 10.109066 , 25.009554 , 10.109066 ,\n",
       "        2.00716  , 10.109066 , 10.109066 , 10.109066 , 25.009554 ,\n",
       "       25.009554 , 10.109066 ,  4.1311665, 10.109066 , 25.009554 ,\n",
       "        2.00716  , 10.109066 ,  2.00716  , 10.109066 ,  4.1311665,\n",
       "       25.009554 , 25.009554 , 25.009554 , 25.009554 ,  2.00716  ,\n",
       "        4.1311665, 10.109066 ,  2.00716  ,  2.00716  , 10.109066 ,\n",
       "        4.1311665,  2.00716  , 25.009554 , 10.109066 , 25.009554 ,\n",
       "        4.1311665, 10.109066 ,  4.1311665, 25.009554 , 10.109066 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = preds[y_test==2]\n",
    "p4 = preds[y_test==4]\n",
    "p10 = preds[y_test==10]\n",
    "p25 = preds[y_test==25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07330584099461963"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(t_test_2, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017204395864553135"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(t_test_4, p4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01189539443294052"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(t_test_10, p10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.127718294621445e-05"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(t_test_25, p25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.image import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = os.walk(os.path.join(data_dir, \"10x10_15mm_v2_8bit_test\"))\n",
    "folder, _, files = next(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/storage/yw18581/data/10x10_15mm_v2_8bit_test'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['File_0_15mm_mask_1891.tiff',\n",
       " 'File_10_15mm_mask_1909.tiff',\n",
       " 'File_11_15mm_mask_1888.tiff',\n",
       " 'File_12_15mm_mask_1888.tiff',\n",
       " 'File_13_15mm_mask_1885.tiff',\n",
       " 'File_14_15mm_mask_1887.tiff',\n",
       " 'File_15_15mm_mask_1896.tiff',\n",
       " 'File_16_15mm_mask_1892.tiff',\n",
       " 'File_17_15mm_mask_1881.tiff',\n",
       " 'File_1_15mm_mask_1902.tiff',\n",
       " 'File_2_15mm_mask_1898.tiff',\n",
       " 'File_3_15mm_mask_1883.tiff',\n",
       " 'File_4_15mm_mask_1887.tiff',\n",
       " 'File_5_15mm_mask_1888.tiff',\n",
       " 'File_6_15mm_mask_1902.tiff',\n",
       " 'File_7_15mm_mask_1889.tiff',\n",
       " 'File_8_15mm_mask_1885.tiff',\n",
       " 'File_9_15mm_mask_1890.tiff']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_15 = [os.path.join(folder, f) for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/storage/yw18581/data/10x10_15mm_v2_8bit_test/File_0_15mm_mask_1891.tiff',\n",
       " '/storage/yw18581/data/10x10_15mm_v2_8bit_test/File_10_15mm_mask_1909.tiff',\n",
       " '/storage/yw18581/data/10x10_15mm_v2_8bit_test/File_11_15mm_mask_1888.tiff',\n",
       " '/storage/yw18581/data/10x10_15mm_v2_8bit_test/File_12_15mm_mask_1888.tiff',\n",
       " '/storage/yw18581/data/10x10_15mm_v2_8bit_test/File_13_15mm_mask_1885.tiff',\n",
       " '/storage/yw18581/data/10x10_15mm_v2_8bit_test/File_14_15mm_mask_1887.tiff',\n",
       " '/storage/yw18581/data/10x10_15mm_v2_8bit_test/File_15_15mm_mask_1896.tiff',\n",
       " '/storage/yw18581/data/10x10_15mm_v2_8bit_test/File_16_15mm_mask_1892.tiff',\n",
       " '/storage/yw18581/data/10x10_15mm_v2_8bit_test/File_17_15mm_mask_1881.tiff',\n",
       " '/storage/yw18581/data/10x10_15mm_v2_8bit_test/File_1_15mm_mask_1902.tiff',\n",
       " '/storage/yw18581/data/10x10_15mm_v2_8bit_test/File_2_15mm_mask_1898.tiff',\n",
       " '/storage/yw18581/data/10x10_15mm_v2_8bit_test/File_3_15mm_mask_1883.tiff',\n",
       " '/storage/yw18581/data/10x10_15mm_v2_8bit_test/File_4_15mm_mask_1887.tiff',\n",
       " '/storage/yw18581/data/10x10_15mm_v2_8bit_test/File_5_15mm_mask_1888.tiff',\n",
       " '/storage/yw18581/data/10x10_15mm_v2_8bit_test/File_6_15mm_mask_1902.tiff',\n",
       " '/storage/yw18581/data/10x10_15mm_v2_8bit_test/File_7_15mm_mask_1889.tiff',\n",
       " '/storage/yw18581/data/10x10_15mm_v2_8bit_test/File_8_15mm_mask_1885.tiff',\n",
       " '/storage/yw18581/data/10x10_15mm_v2_8bit_test/File_9_15mm_mask_1890.tiff']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_15 = [imread(fp)[ROW_SLICE,COL_SLICE] for fp in gt_15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 1400\n",
    "IMG_HEIGHT = 1400\n",
    "ROW_SLICE = slice(0, 1400)\n",
    "COL_SLICE = slice(1000, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_15_cut = cut_X(np.asarray(X_15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds15 = model.predict(X_15_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25.009554],\n",
       "       [25.009554],\n",
       "       [25.009554],\n",
       "       [25.009554],\n",
       "       [25.009554],\n",
       "       [25.009554],\n",
       "       [25.009554],\n",
       "       [25.009554],\n",
       "       [25.009554],\n",
       "       [25.009554],\n",
       "       [25.009554],\n",
       "       [25.009554],\n",
       "       [25.009554],\n",
       "       [25.009554],\n",
       "       [25.009554],\n",
       "       [25.009554],\n",
       "       [25.009554],\n",
       "       [25.009554]], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
