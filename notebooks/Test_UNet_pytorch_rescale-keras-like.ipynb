{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Transformers import UNetDataset, ChannelsFirst, ToTensor, Rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_DEEPTHOUGHT=\"/storage/yw18581/data\"\n",
    "data_dir = DATA_DIR_DEEPTHOUGHT\n",
    "train_test = os.path.join(data_dir, \"train_validation_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"/storage/yw18581/data/train_validation_test/Xy_train+val_clean_300_24_10_25.npz\")\n",
    "x = data[\"x\"]\n",
    "y = data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "composed = transforms.Compose([Rescale(.25), ChannelsFirst(), ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = UNetDataset(x, y, transform=composed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### in UNet_torch_like_keras.py, model defines as the previously used keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from UNet_torch_like_keras import UNet, dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_keras_like = UNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (conv_block_down1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_block_down2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_block_down3): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_block_down4): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_block_down5): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (conv_transpose6): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (conv_block_up6): Sequential(\n",
       "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_transpose7): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (conv_block_up7): Sequential(\n",
       "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_transpose8): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (conv_block_up8): Sequential(\n",
       "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_transpose9): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (conv_block_up9): Sequential(\n",
       "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_last): Sequential(\n",
       "    (0): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_keras_like.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(net_keras_like.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "\n",
      "[1,    30] loss: -0.028\n",
      "[1,    60] loss: -0.057\n",
      "Epoch 2\n",
      "\n",
      "[2,    30] loss: -0.027\n",
      "[2,    60] loss: -0.058\n",
      "Epoch 3\n",
      "\n",
      "[3,    30] loss: -0.030\n",
      "[3,    60] loss: -0.058\n",
      "Epoch 4\n",
      "\n",
      "[4,    30] loss: -0.030\n",
      "[4,    60] loss: -0.058\n",
      "Epoch 5\n",
      "\n",
      "[5,    30] loss: -0.029\n",
      "[5,    60] loss: -0.060\n",
      "Epoch 6\n",
      "\n",
      "[6,    30] loss: -0.032\n",
      "[6,    60] loss: -0.065\n",
      "Epoch 7\n",
      "\n",
      "[7,    30] loss: -0.040\n",
      "[7,    60] loss: -0.104\n",
      "Epoch 8\n",
      "\n",
      "[8,    30] loss: -0.232\n",
      "[8,    60] loss: -0.832\n",
      "Epoch 9\n",
      "\n",
      "[9,    30] loss: -0.711\n",
      "[9,    60] loss: -1.491\n",
      "Epoch 10\n",
      "\n",
      "[10,    30] loss: -0.806\n",
      "[10,    60] loss: -1.624\n",
      "Epoch 11\n",
      "\n",
      "[11,    30] loss: -0.832\n",
      "[11,    60] loss: -1.670\n",
      "Epoch 12\n",
      "\n",
      "[12,    30] loss: -0.846\n",
      "[12,    60] loss: -1.705\n",
      "Epoch 13\n",
      "\n",
      "[13,    30] loss: -0.858\n",
      "[13,    60] loss: -1.716\n",
      "Epoch 14\n",
      "\n",
      "[14,    30] loss: -0.870\n",
      "[14,    60] loss: -1.743\n",
      "Epoch 15\n",
      "\n",
      "[15,    30] loss: -0.875\n",
      "[15,    60] loss: -1.755\n",
      "Epoch 16\n",
      "\n",
      "[16,    30] loss: -0.888\n",
      "[16,    60] loss: -1.773\n",
      "Epoch 17\n",
      "\n",
      "[17,    30] loss: -0.886\n",
      "[17,    60] loss: -1.766\n",
      "Epoch 18\n",
      "\n",
      "[18,    30] loss: -0.888\n",
      "[18,    60] loss: -1.779\n",
      "Epoch 19\n",
      "\n",
      "[19,    30] loss: -0.895\n",
      "[19,    60] loss: -1.786\n",
      "Epoch 20\n",
      "\n",
      "[20,    30] loss: -0.896\n",
      "[20,    60] loss: -1.789\n",
      "Epoch 21\n",
      "\n",
      "[21,    30] loss: -0.901\n",
      "[21,    60] loss: -1.801\n",
      "Epoch 22\n",
      "\n",
      "[22,    30] loss: -0.902\n",
      "[22,    60] loss: -1.794\n",
      "Epoch 23\n",
      "\n",
      "[23,    30] loss: -0.906\n",
      "[23,    60] loss: -1.807\n",
      "Epoch 24\n",
      "\n",
      "[24,    30] loss: -0.896\n",
      "[24,    60] loss: -1.797\n",
      "Epoch 25\n",
      "\n",
      "[25,    30] loss: -0.900\n",
      "[25,    60] loss: -1.800\n",
      "Epoch 26\n",
      "\n",
      "[26,    30] loss: -0.907\n",
      "[26,    60] loss: -1.818\n",
      "Epoch 27\n",
      "\n",
      "[27,    30] loss: -0.903\n",
      "[27,    60] loss: -1.813\n",
      "Epoch 28\n",
      "\n",
      "[28,    30] loss: -0.908\n",
      "[28,    60] loss: -1.815\n",
      "Epoch 29\n",
      "\n",
      "[29,    30] loss: -0.902\n",
      "[29,    60] loss: -1.816\n",
      "Epoch 30\n",
      "\n",
      "[30,    30] loss: -0.910\n",
      "[30,    60] loss: -1.820\n",
      "Epoch 31\n",
      "\n",
      "[31,    30] loss: -0.912\n",
      "[31,    60] loss: -1.822\n",
      "Epoch 32\n",
      "\n",
      "[32,    30] loss: -0.916\n",
      "[32,    60] loss: -1.827\n",
      "Epoch 33\n",
      "\n",
      "[33,    30] loss: -0.914\n",
      "[33,    60] loss: -1.830\n",
      "Epoch 34\n",
      "\n",
      "[34,    30] loss: -0.914\n",
      "[34,    60] loss: -1.827\n",
      "Epoch 35\n",
      "\n",
      "[35,    30] loss: -0.915\n",
      "[35,    60] loss: -1.832\n",
      "Epoch 36\n",
      "\n",
      "[36,    30] loss: -0.915\n",
      "[36,    60] loss: -1.830\n",
      "Epoch 37\n",
      "\n",
      "[37,    30] loss: -0.914\n",
      "[37,    60] loss: -1.829\n",
      "Epoch 38\n",
      "\n",
      "[38,    30] loss: -0.911\n",
      "[38,    60] loss: -1.825\n",
      "Epoch 39\n",
      "\n",
      "[39,    30] loss: -0.917\n",
      "[39,    60] loss: -1.836\n",
      "Epoch 40\n",
      "\n",
      "[40,    30] loss: -0.914\n",
      "[40,    60] loss: -1.830\n",
      "Epoch 41\n",
      "\n",
      "[41,    30] loss: -0.917\n",
      "[41,    60] loss: -1.836\n",
      "Epoch 42\n",
      "\n",
      "[42,    30] loss: -0.917\n",
      "[42,    60] loss: -1.835\n",
      "Epoch 43\n",
      "\n",
      "[43,    30] loss: -0.918\n",
      "[43,    60] loss: -1.836\n",
      "Epoch 44\n",
      "\n",
      "[44,    30] loss: -0.911\n",
      "[44,    60] loss: -1.824\n",
      "Epoch 45\n",
      "\n",
      "[45,    30] loss: -0.916\n",
      "[45,    60] loss: -1.835\n",
      "Epoch 46\n",
      "\n",
      "[46,    30] loss: -0.919\n",
      "[46,    60] loss: -1.840\n",
      "Epoch 47\n",
      "\n",
      "[47,    30] loss: -0.921\n",
      "[47,    60] loss: -1.840\n",
      "Epoch 48\n",
      "\n",
      "[48,    30] loss: -0.918\n",
      "[48,    60] loss: -1.834\n",
      "Epoch 49\n",
      "\n",
      "[49,    30] loss: -0.918\n",
      "[49,    60] loss: -1.842\n",
      "Epoch 50\n",
      "\n",
      "[50,    30] loss: -0.917\n",
      "[50,    60] loss: -1.839\n",
      "Epoch 51\n",
      "\n",
      "[51,    30] loss: -0.911\n",
      "[51,    60] loss: -1.827\n",
      "Epoch 52\n",
      "\n",
      "[52,    30] loss: -0.923\n",
      "[52,    60] loss: -1.838\n",
      "Epoch 53\n",
      "\n",
      "[53,    30] loss: -0.913\n",
      "[53,    60] loss: -1.835\n",
      "Epoch 54\n",
      "\n",
      "[54,    30] loss: -0.920\n",
      "[54,    60] loss: -1.842\n",
      "Epoch 55\n",
      "\n",
      "[55,    30] loss: -0.922\n",
      "[55,    60] loss: -1.846\n",
      "Epoch 56\n",
      "\n",
      "[56,    30] loss: -0.919\n",
      "[56,    60] loss: -1.839\n",
      "Epoch 57\n",
      "\n",
      "[57,    30] loss: -0.918\n",
      "[57,    60] loss: -1.838\n",
      "Epoch 58\n",
      "\n",
      "[58,    30] loss: -0.924\n",
      "[58,    60] loss: -1.848\n",
      "Epoch 59\n",
      "\n",
      "[59,    30] loss: -0.925\n",
      "[59,    60] loss: -1.846\n",
      "Epoch 60\n",
      "\n",
      "[60,    30] loss: -0.923\n",
      "[60,    60] loss: -1.844\n",
      "Epoch 61\n",
      "\n",
      "[61,    30] loss: -0.923\n",
      "[61,    60] loss: -1.845\n",
      "Epoch 62\n",
      "\n",
      "[62,    30] loss: -0.925\n",
      "[62,    60] loss: -1.849\n",
      "Epoch 63\n",
      "\n",
      "[63,    30] loss: -0.918\n",
      "[63,    60] loss: -1.844\n",
      "Epoch 64\n",
      "\n",
      "[64,    30] loss: -0.927\n",
      "[64,    60] loss: -1.849\n",
      "Epoch 65\n",
      "\n",
      "[65,    30] loss: -0.926\n",
      "[65,    60] loss: -1.850\n",
      "Epoch 66\n",
      "\n",
      "[66,    30] loss: -0.916\n",
      "[66,    60] loss: -1.836\n",
      "Epoch 67\n",
      "\n",
      "[67,    30] loss: -0.923\n",
      "[67,    60] loss: -1.846\n",
      "Epoch 68\n",
      "\n",
      "[68,    30] loss: -0.924\n",
      "[68,    60] loss: -1.842\n",
      "Epoch 69\n",
      "\n",
      "[69,    30] loss: -0.926\n",
      "[69,    60] loss: -1.848\n",
      "Epoch 70\n",
      "\n",
      "[70,    30] loss: -0.925\n",
      "[70,    60] loss: -1.850\n",
      "Epoch 71\n",
      "\n",
      "[71,    30] loss: -0.927\n",
      "[71,    60] loss: -1.853\n",
      "Epoch 72\n",
      "\n",
      "[72,    30] loss: -0.925\n",
      "[72,    60] loss: -1.853\n",
      "Epoch 73\n",
      "\n",
      "[73,    30] loss: -0.923\n",
      "[73,    60] loss: -1.851\n",
      "Epoch 74\n",
      "\n",
      "[74,    30] loss: -0.924\n",
      "[74,    60] loss: -1.846\n",
      "Epoch 75\n",
      "\n",
      "[75,    30] loss: -0.927\n",
      "[75,    60] loss: -1.855\n",
      "Epoch 76\n",
      "\n",
      "[76,    30] loss: -0.926\n",
      "[76,    60] loss: -1.853\n",
      "Epoch 77\n",
      "\n",
      "[77,    30] loss: -0.927\n",
      "[77,    60] loss: -1.855\n",
      "Epoch 78\n",
      "\n",
      "[78,    30] loss: -0.926\n",
      "[78,    60] loss: -1.855\n",
      "Epoch 79\n",
      "\n",
      "[79,    30] loss: -0.929\n",
      "[79,    60] loss: -1.849\n",
      "Epoch 80\n",
      "\n",
      "[80,    30] loss: -0.927\n",
      "[80,    60] loss: -1.856\n",
      "Epoch 81\n",
      "\n",
      "[81,    30] loss: -0.926\n",
      "[81,    60] loss: -1.856\n",
      "Epoch 82\n",
      "\n",
      "[82,    30] loss: -0.926\n",
      "[82,    60] loss: -1.857\n",
      "Epoch 83\n",
      "\n",
      "[83,    30] loss: -0.931\n",
      "[83,    60] loss: -1.857\n",
      "Epoch 84\n",
      "\n",
      "[84,    30] loss: -0.929\n",
      "[84,    60] loss: -1.860\n",
      "Epoch 85\n",
      "\n",
      "[85,    30] loss: -0.931\n",
      "[85,    60] loss: -1.859\n",
      "Epoch 86\n",
      "\n",
      "[86,    30] loss: -0.929\n",
      "[86,    60] loss: -1.856\n",
      "Epoch 87\n",
      "\n",
      "[87,    30] loss: -0.928\n",
      "[87,    60] loss: -1.853\n",
      "Epoch 88\n",
      "\n",
      "[88,    30] loss: -0.929\n",
      "[88,    60] loss: -1.855\n",
      "Epoch 89\n",
      "\n",
      "[89,    30] loss: -0.929\n",
      "[89,    60] loss: -1.856\n",
      "Epoch 90\n",
      "\n",
      "[90,    30] loss: -0.932\n",
      "[90,    60] loss: -1.862\n",
      "Epoch 91\n",
      "\n",
      "[91,    30] loss: -0.929\n",
      "[91,    60] loss: -1.854\n",
      "Epoch 92\n",
      "\n",
      "[92,    30] loss: -0.929\n",
      "[92,    60] loss: -1.861\n",
      "Epoch 93\n",
      "\n",
      "[93,    30] loss: -0.926\n",
      "[93,    60] loss: -1.858\n",
      "Epoch 94\n",
      "\n",
      "[94,    30] loss: -0.931\n",
      "[94,    60] loss: -1.860\n",
      "Epoch 95\n",
      "\n",
      "[95,    30] loss: -0.930\n",
      "[95,    60] loss: -1.863\n",
      "Epoch 96\n",
      "\n",
      "[96,    30] loss: -0.931\n",
      "[96,    60] loss: -1.862\n",
      "Epoch 97\n",
      "\n",
      "[97,    30] loss: -0.932\n",
      "[97,    60] loss: -1.863\n",
      "Epoch 98\n",
      "\n",
      "[98,    30] loss: -0.933\n",
      "[98,    60] loss: -1.865\n",
      "Epoch 99\n",
      "\n",
      "[99,    30] loss: -0.934\n",
      "[99,    60] loss: -1.865\n",
      "Epoch 100\n",
      "\n",
      "[100,    30] loss: -0.931\n",
      "[100,    60] loss: -1.865\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    print(\"Epoch {}\\n\".format(epoch+1))\n",
    "    running_loss = 0.0\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        inputs = batch['image'].float().to(device)\n",
    "        labels = batch['mask'].float().to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net_keras_like(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 30 == 29:    # print every 2000 mini_batches\n",
    "            print('[%d, %5d] loss: %.3f' % \n",
    "                 (epoch + 1, i + 1, running_loss / 30))\n",
    "    if epoch % 25 == 24:\n",
    "        plt.imshow(outputs[0][0,...].cpu().detach().numpy(), cmap='gray')\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff565dbce10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(outputs[2][0,...].cpu().detach().numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.load(\"/storage/yw18581/data/train_validation_test/Xy_test_clean_300_24_10_25.npz\")\n",
    "x_test = test_data[\"x\"]\n",
    "y_test = test_data['y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataset = UNetDataset(x_test, y_test, transform=composed)\n",
    "\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=16, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([16, 1, 350, 350]) torch.Size([16, 1, 350, 350])\n",
      "1 torch.Size([16, 1, 350, 350]) torch.Size([16, 1, 350, 350])\n",
      "2 torch.Size([16, 1, 350, 350]) torch.Size([16, 1, 350, 350])\n",
      "3 torch.Size([16, 1, 350, 350]) torch.Size([16, 1, 350, 350])\n",
      "4 torch.Size([16, 1, 350, 350]) torch.Size([16, 1, 350, 350])\n"
     ]
    }
   ],
   "source": [
    "for i, test_batch in enumerate(test_data_loader):\n",
    "    print(i, test_batch['image'].shape, test_batch['mask'].shape)\n",
    "    if i==4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(test_inputs)):    \n",
    "    f = plt.figure()\n",
    "    f.add_subplot(1,2, 1)\n",
    "    plt.imshow(preds[i][0,...].cpu().detach().numpy(), cmap='gray')\n",
    "    f.add_subplot(1,2, 2)\n",
    "    plt.imshow(test_labels[i][0,...].cpu().detach().numpy(), cmap='gray')\n",
    "    plt.show(block=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net_keras_like.state_dict(), \"../model/trained_UNet_pytorch_keras-like_100epochs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inference = UNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (conv_block_down1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_block_down2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_block_down3): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_block_down4): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_block_down5): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (conv_transpose6): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (conv_block_up6): Sequential(\n",
       "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_transpose7): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (conv_block_up7): Sequential(\n",
       "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_transpose8): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (conv_block_up8): Sequential(\n",
       "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_transpose9): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (conv_block_up9): Sequential(\n",
       "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_last): Sequential(\n",
       "    (0): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inference.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (conv_block_down1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_block_down2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_block_down3): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_block_down4): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_block_down5): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (conv_transpose6): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (conv_block_up6): Sequential(\n",
       "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_transpose7): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (conv_block_up7): Sequential(\n",
       "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_transpose8): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (conv_block_up8): Sequential(\n",
       "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_transpose9): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (conv_block_up9): Sequential(\n",
       "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_last): Sequential(\n",
       "    (0): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inference.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inference.load_state_dict(torch.load(\"../model/trained_UNet_pytorch_keras-like_100epochs.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-d0dd7894da86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtest_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fluffy-bunnies/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/yw18581/src/leaf_reco/UNet_torch_like_keras.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mconvb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_block_down1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;31m#print('convb1: {}'.format(convb1.size()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mpool1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fluffy-bunnies/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fluffy-bunnies/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fluffy-bunnies/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fluffy-bunnies/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fluffy-bunnies/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    338\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    339\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 340\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for i, test_batch in enumerate(test_data_loader):\n",
    "    test_inputs = test_batch['image'].float().to(device)\n",
    "    test_labels = test_batch['mask'].float().to(device)\n",
    "    preds = model_inference(test_inputs)\n",
    "    predictions.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 350, 350])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.5138e-06, 6.4526e-12, 8.9250e-15,  ..., 7.7720e-16,\n",
       "           8.1648e-11, 3.7575e-06],\n",
       "          [1.0631e-11, 2.1511e-22, 4.4686e-28,  ..., 1.5572e-30,\n",
       "           8.9686e-21, 7.3041e-12],\n",
       "          [2.9637e-15, 2.4948e-29, 3.5770e-37,  ..., 0.0000e+00,\n",
       "           2.6086e-27, 2.5118e-15],\n",
       "          ...,\n",
       "          [1.7652e-22, 0.0000e+00, 0.0000e+00,  ..., 5.8688e-29,\n",
       "           1.2711e-19, 1.8142e-11],\n",
       "          [5.2850e-15, 9.6984e-30, 5.2541e-38,  ..., 5.5311e-19,\n",
       "           4.9912e-13, 1.3828e-07],\n",
       "          [1.1233e-08, 3.0573e-17, 1.3672e-22,  ..., 1.1917e-11,\n",
       "           3.7427e-08, 4.3065e-05]]],\n",
       "\n",
       "\n",
       "        [[[1.3923e-06, 5.4662e-12, 7.2003e-15,  ..., 1.1514e-15,\n",
       "           1.0565e-10, 4.3107e-06],\n",
       "          [9.0820e-12, 1.5632e-22, 2.9512e-28,  ..., 3.3939e-30,\n",
       "           1.5046e-20, 9.7218e-12],\n",
       "          [2.4090e-15, 1.6422e-29, 2.0687e-37,  ..., 0.0000e+00,\n",
       "           5.2170e-27, 3.6732e-15],\n",
       "          ...,\n",
       "          [1.6463e-22, 0.0000e+00, 0.0000e+00,  ..., 4.1855e-29,\n",
       "           1.0095e-19, 1.5901e-11],\n",
       "          [5.0530e-15, 8.8687e-30, 4.6949e-38,  ..., 4.4333e-19,\n",
       "           4.2984e-13, 1.2734e-07],\n",
       "          [1.0966e-08, 2.9099e-17, 1.2816e-22,  ..., 1.0425e-11,\n",
       "           3.4160e-08, 4.0871e-05]]],\n",
       "\n",
       "\n",
       "        [[[1.3000e-06, 4.7842e-12, 6.0901e-15,  ..., 1.4229e-15,\n",
       "           1.2080e-10, 4.6229e-06],\n",
       "          [7.9598e-12, 1.2041e-22, 2.1235e-28,  ..., 5.1039e-30,\n",
       "           1.9518e-20, 1.1179e-11],\n",
       "          [2.0192e-15, 1.1584e-29, 1.3264e-37,  ..., 3.6579e-39,\n",
       "           7.2670e-27, 4.3865e-15],\n",
       "          ...,\n",
       "          [1.6779e-22, 0.0000e+00, 0.0000e+00,  ..., 5.6891e-29,\n",
       "           1.2469e-19, 1.7964e-11],\n",
       "          [5.1150e-15, 9.1063e-30, 4.8766e-38,  ..., 5.4093e-19,\n",
       "           4.9292e-13, 1.3755e-07],\n",
       "          [1.1032e-08, 2.9509e-17, 1.3107e-22,  ..., 1.1756e-11,\n",
       "           3.7119e-08, 4.2905e-05]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[1.7153e-06, 8.2369e-12, 1.2144e-14,  ..., 6.5663e-16,\n",
       "           7.2923e-11, 3.5353e-06],\n",
       "          [1.3556e-11, 3.5068e-22, 8.3016e-28,  ..., 1.1082e-30,\n",
       "           7.1395e-21, 6.4297e-12],\n",
       "          [4.1504e-15, 4.8772e-29, 8.4485e-37,  ..., 0.0000e+00,\n",
       "           1.9204e-27, 2.1205e-15],\n",
       "          ...,\n",
       "          [2.0689e-22, 0.0000e+00, 0.0000e+00,  ..., 2.9187e-29,\n",
       "           8.0795e-20, 1.4100e-11],\n",
       "          [5.8231e-15, 1.1856e-29, 6.8190e-38,  ..., 3.5161e-19,\n",
       "           3.7181e-13, 1.1793e-07],\n",
       "          [1.1829e-08, 3.4158e-17, 1.5858e-22,  ..., 9.0738e-12,\n",
       "           3.1289e-08, 3.8880e-05]]],\n",
       "\n",
       "\n",
       "        [[[1.5245e-06, 6.5515e-12, 9.1205e-15,  ..., 1.2854e-15,\n",
       "           1.1360e-10, 4.4815e-06],\n",
       "          [1.0816e-11, 2.2348e-22, 4.7033e-28,  ..., 4.1960e-30,\n",
       "           1.7313e-20, 1.0492e-11],\n",
       "          [3.0576e-15, 2.6586e-29, 3.8903e-37,  ..., 0.0000e+00,\n",
       "           6.2380e-27, 4.0397e-15],\n",
       "          ...,\n",
       "          [1.8780e-22, 0.0000e+00, 0.0000e+00,  ..., 5.9830e-29,\n",
       "           1.2863e-19, 1.8246e-11],\n",
       "          [5.5046e-15, 1.0553e-29, 5.8700e-38,  ..., 5.6146e-19,\n",
       "           5.0347e-13, 1.3884e-07],\n",
       "          [1.1492e-08, 3.2078e-17, 1.4570e-22,  ..., 1.2029e-11,\n",
       "           3.7592e-08, 4.3134e-05]]],\n",
       "\n",
       "\n",
       "        [[[1.4858e-06, 6.2307e-12, 8.5504e-15,  ..., 1.0050e-15,\n",
       "           9.6047e-11, 4.0955e-06],\n",
       "          [1.0299e-11, 2.0262e-22, 4.1484e-28,  ..., 2.5900e-30,\n",
       "           1.2420e-20, 8.7162e-12],\n",
       "          [2.8654e-15, 2.3345e-29, 3.2925e-37,  ..., 0.0000e+00,\n",
       "           4.0198e-27, 3.1673e-15],\n",
       "          ...,\n",
       "          [1.7924e-22, 0.0000e+00, 0.0000e+00,  ..., 4.1435e-29,\n",
       "           9.8626e-20, 1.5613e-11],\n",
       "          [5.3344e-15, 9.9013e-30, 5.4042e-38,  ..., 4.4170e-19,\n",
       "           4.2421e-13, 1.2594e-07],\n",
       "          [1.1286e-08, 3.0905e-17, 1.3887e-22,  ..., 1.0429e-11,\n",
       "           3.3948e-08, 4.0592e-05]]]], device='cuda:0',\n",
       "       grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inference(test_image.float().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 120.00 MiB (GPU 0; 11.91 GiB total capacity; 11.15 GiB already allocated; 54.69 MiB free; 174.82 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-27fc9428a277>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fluffy-bunnies/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/yw18581/src/leaf_reco/UNet_torch_like_keras.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mup8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvb2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m#print('cat: {}'.format(x.size()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mconvb8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_block_up8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;31m#print('convb8: {}'.format(convb8.size()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fluffy-bunnies/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fluffy-bunnies/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fluffy-bunnies/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fluffy-bunnies/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fluffy-bunnies/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    338\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    339\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 340\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 120.00 MiB (GPU 0; 11.91 GiB total capacity; 11.15 GiB already allocated; 54.69 MiB free; 174.82 MiB cached)"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(test_data_loader):\n",
    "    test_image, test_mask = batch['image'], batch['mask']\n",
    "    pred = model_inference(test_image.float().to(device))\n",
    "    f = plt.figure()\n",
    "    f.add_subplot(1,3, 1)\n",
    "    plt.imshow(test_image[i][0,...], cmap='gray')\n",
    "    f.add_subplot(1,3, 2)\n",
    "    plt.imshow(test_mask[i][0,...], cmap='gray')\n",
    "    f.add_subplot(1,3, 3)\n",
    "    plt.imshow(pred[i][0,...].cpu().detach().numpy(), cmap='gray')\n",
    "    plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
