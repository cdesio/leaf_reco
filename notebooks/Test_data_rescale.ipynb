{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.15.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skimage.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from skimage import io, transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.utils.data as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_DEEPTHOUGHT=\"/storage/yw18581/data\"\n",
    "data_dir = DATA_DIR_DEEPTHOUGHT\n",
    "train_test = os.path.join(data_dir, \"train_validation_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"/storage/yw18581/data/train_validation_test/Xy_train+val_clean_300_24_10_25.npz\")\n",
    "x = data[\"x\"]\n",
    "y = data['y']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_x = torch.from_numpy(x) # transform to torch tensors\n",
    "tensor_y = torch.from_numpy(y)\n",
    "\n",
    "xy_dataset = utils.TensorDataset(tensor_x,tensor_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetDataset(Dataset):\n",
    "    def __init__(self, X, Y, transform=None):\n",
    "        self.transform = transform\n",
    "        self._X = X\n",
    "        self._Y = Y\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self._X[idx]\n",
    "        mask = self._Y[idx]\n",
    "        sample = {'image': image, 'masks': mask}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._X)\n",
    "\n",
    "\n",
    "class ChannelsFirst:\n",
    "    def __call__(self, sample):\n",
    "        image, mask = sample['image'], sample['masks']\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.swapaxes(2,0)\n",
    "        mask = mask.swapaxes(2,0)\n",
    "        return {'image': image,\n",
    "                'masks': mask}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "resizer = transforms.Resize(350)\n",
    "out_image = resizer(image)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python \n",
    "\n",
    "from skimage.transform import rescale\n",
    "from functools import partial\n",
    "\n",
    "resizer = partial(rescale, scale=0.25, anti_aliasing=True, multichannel=True)\n",
    "out_image = resizer(image)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Rescale:\n",
    "    \n",
    "    def __init__(self, scale):\n",
    "        assert isinstance(scale, float)\n",
    "        self.output_scale = scale\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image, mask = sample['image'], sample['masks']\n",
    "\n",
    "        resizer = partial(rescale, scale=self.output_scale, anti_aliasing=True, multichannel=True)\n",
    "        out_image = resizer(image)\n",
    "        out_mask = resizer(mask)\n",
    "\n",
    "        return {'image': out_image,\n",
    "                'masks': out_mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor:\n",
    "    def __call__(self, sample):\n",
    "        image, mask = sample['image'], sample['masks']\n",
    "        img_tensor = torch.from_numpy(image)\n",
    "        mask_tensor = torch.from_numpy(mask)\n",
    "        return {'image': img_tensor,\n",
    "               'masks': mask_tensor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "composed = transforms.Compose([Rescale(0.25), ChannelsFirst(), ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = UNetDataset(x,y, transform=composed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 350, 350]) torch.float64\n",
      "torch.Size([4, 1, 350, 350]) torch.float64\n",
      "torch.Size([4, 1, 350, 350]) torch.float64\n",
      "torch.Size([4, 1, 350, 350]) torch.float64\n",
      "torch.Size([4, 1, 350, 350]) torch.float64\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(dataloader):\n",
    "    print(batch['image'].size(), batch['image'].dtype)\n",
    "    if i==4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "resizer = partial(rescale, scale=.25, anti_aliasing=True, multichannel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.asarray(list(map(resizer, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 350, 350, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 1, 350, 350)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_resize = x1.swapaxes(3, 1)\n",
    "x_resize.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = map(lambda x: x, range(10))\n",
    "np.fromiter(m, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 1, 350, 350)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resize = np.asarray(list(map(resizer, y)))\n",
    "y_resize = y_resize.swapaxes(3, 1)\n",
    "\n",
    "y_resize.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"/storage/yw18581/data/train_validation_test/Xy_train+val_clean_300_24_10_25_resized_ch_first.npz\",\n",
    "                   x = x_resize, y=y_resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale(x[...,0][0], 1./4., anti_aliasing=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped = []\n",
    "for i in range(x.shape[0]):\n",
    "    print(i)\n",
    "    reshaped.append(rescale(x[...,0][i], 1./4., anti_aliasing=True))\n",
    "reshaped = np.asarray(reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
