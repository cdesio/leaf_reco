{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr  9 12:52:12 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 410.73       Driver Version: 410.73       CUDA Version: 10.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 760     Off  | 00000000:01:00.0 N/A |                  N/A |\r\n",
      "| 38%   42C    P8    N/A /  N/A |     26MiB /  4034MiB |     N/A      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce GTX 760     Off  | 00000000:06:00.0 N/A |                  N/A |\r\n",
      "| 38%   41C    P8    N/A /  N/A |      1MiB /  4037MiB |     N/A      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0                    Not Supported                                       |\r\n",
      "|    1                    Not Supported                                       |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 340, 800, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 340, 800, 16)      160       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 340, 800, 16)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 340, 800, 16)      64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 170, 400, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 170, 400, 32)      4640      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 170, 400, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 170, 400, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 85, 200, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 85, 200, 64)       18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 85, 200, 64)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 85, 200, 64)       256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 42, 100, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 268800)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                4300816   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 4,324,697\n",
      "Trainable params: 4,324,441\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "[INFO] training model...\n",
      "Train on 768 samples, validate on 192 samples\n",
      "Epoch 1/200\n",
      "768/768 [==============================] - 22s 28ms/step - loss: 99.4274 - val_loss: 42.4215\n",
      "Epoch 2/200\n",
      "768/768 [==============================] - 17s 22ms/step - loss: 51.5671 - val_loss: 19.2777\n",
      "Epoch 3/200\n",
      "768/768 [==============================] - 18s 23ms/step - loss: 43.3328 - val_loss: 23.7832\n",
      "Epoch 4/200\n",
      "768/768 [==============================] - 18s 23ms/step - loss: 35.1829 - val_loss: 25.0623\n",
      "Epoch 5/200\n",
      "768/768 [==============================] - 18s 24ms/step - loss: 36.1758 - val_loss: 22.6437\n",
      "Epoch 6/200\n",
      "768/768 [==============================] - 18s 24ms/step - loss: 33.3484 - val_loss: 22.9971\n",
      "Epoch 7/200\n",
      "768/768 [==============================] - 19s 24ms/step - loss: 30.5932 - val_loss: 13.2827\n",
      "Epoch 8/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 30.8326 - val_loss: 18.0429\n",
      "Epoch 9/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 30.3487 - val_loss: 14.1612\n",
      "Epoch 10/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 27.9769 - val_loss: 15.7002\n",
      "Epoch 11/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 29.9668 - val_loss: 17.2552\n",
      "Epoch 12/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 26.7247 - val_loss: 17.6246\n",
      "Epoch 13/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 28.5832 - val_loss: 20.2712\n",
      "Epoch 14/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 26.5193 - val_loss: 17.1496\n",
      "Epoch 15/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 24.4066 - val_loss: 11.5057\n",
      "Epoch 16/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 24.8370 - val_loss: 10.8369\n",
      "Epoch 17/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 21.5866 - val_loss: 15.9459\n",
      "Epoch 18/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 23.8498 - val_loss: 12.0476\n",
      "Epoch 19/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 22.6161 - val_loss: 14.9178\n",
      "Epoch 20/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 25.6341 - val_loss: 9.8179\n",
      "Epoch 21/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 20.2438 - val_loss: 11.6312\n",
      "Epoch 22/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 22.4878 - val_loss: 9.9850\n",
      "Epoch 23/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 26.2051 - val_loss: 14.3260\n",
      "Epoch 24/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 22.5476 - val_loss: 9.6185\n",
      "Epoch 25/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 22.5130 - val_loss: 8.1012\n",
      "Epoch 26/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 21.8788 - val_loss: 12.6945\n",
      "Epoch 27/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 21.4234 - val_loss: 7.9740\n",
      "Epoch 28/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 20.6329 - val_loss: 6.6427\n",
      "Epoch 29/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 20.8799 - val_loss: 6.1763\n",
      "Epoch 30/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 24.0002 - val_loss: 12.2492\n",
      "Epoch 31/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 20.0785 - val_loss: 10.2002\n",
      "Epoch 32/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 19.2380 - val_loss: 7.1949\n",
      "Epoch 33/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 19.6934 - val_loss: 8.5884\n",
      "Epoch 34/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 20.9416 - val_loss: 7.0749\n",
      "Epoch 35/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 20.5183 - val_loss: 11.4636\n",
      "Epoch 36/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 20.1800 - val_loss: 6.1854\n",
      "Epoch 37/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 18.6249 - val_loss: 9.8641\n",
      "Epoch 38/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 18.1284 - val_loss: 7.0336\n",
      "Epoch 39/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 21.1637 - val_loss: 10.5868\n",
      "Epoch 40/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 19.9296 - val_loss: 11.7469\n",
      "Epoch 41/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 18.3508 - val_loss: 8.8549\n",
      "Epoch 42/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 21.7332 - val_loss: 9.8151\n",
      "Epoch 43/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 19.1639 - val_loss: 7.3863\n",
      "Epoch 44/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 18.9841 - val_loss: 8.4523\n",
      "Epoch 45/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 18.7117 - val_loss: 11.2319\n",
      "Epoch 46/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 18.9291 - val_loss: 7.6127\n",
      "Epoch 47/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 20.1299 - val_loss: 6.3496\n",
      "Epoch 48/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 19s 25ms/step - loss: 19.0945 - val_loss: 10.6894\n",
      "Epoch 49/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 19.3432 - val_loss: 7.8791\n",
      "Epoch 50/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.7434 - val_loss: 5.7329\n",
      "Epoch 51/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 20.6159 - val_loss: 9.2945\n",
      "Epoch 52/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 20.0886 - val_loss: 11.1366\n",
      "Epoch 53/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 18.7155 - val_loss: 9.7387\n",
      "Epoch 54/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.5865 - val_loss: 8.7909\n",
      "Epoch 55/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.2325 - val_loss: 10.3860\n",
      "Epoch 56/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 18.0866 - val_loss: 10.5222\n",
      "Epoch 57/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 19.0019 - val_loss: 9.5674\n",
      "Epoch 58/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 18.6062 - val_loss: 8.8501\n",
      "Epoch 59/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 20.4163 - val_loss: 7.6049\n",
      "Epoch 60/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 20.7426 - val_loss: 6.2760\n",
      "Epoch 61/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 18.4264 - val_loss: 9.1211\n",
      "Epoch 62/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 19.2063 - val_loss: 11.9684\n",
      "Epoch 63/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.5183 - val_loss: 8.2978\n",
      "Epoch 64/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.7468 - val_loss: 11.2040\n",
      "Epoch 65/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.6683 - val_loss: 9.0985\n",
      "Epoch 66/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 19.1012 - val_loss: 8.4337\n",
      "Epoch 67/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 18.1714 - val_loss: 7.3644\n",
      "Epoch 68/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 18.0296 - val_loss: 7.8377\n",
      "Epoch 69/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 18.7147 - val_loss: 6.4679\n",
      "Epoch 70/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.9412 - val_loss: 4.7625\n",
      "Epoch 71/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.6134 - val_loss: 12.5175\n",
      "Epoch 72/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 18.0283 - val_loss: 6.2181\n",
      "Epoch 73/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 18.4048 - val_loss: 9.6701\n",
      "Epoch 74/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 19.0290 - val_loss: 8.9451\n",
      "Epoch 75/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.2180 - val_loss: 12.0568\n",
      "Epoch 76/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 15.2201 - val_loss: 6.7344\n",
      "Epoch 77/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 15.9883 - val_loss: 11.2722\n",
      "Epoch 78/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.4415 - val_loss: 8.3952\n",
      "Epoch 79/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 19.2420 - val_loss: 5.0607\n",
      "Epoch 80/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.3391 - val_loss: 6.7844\n",
      "Epoch 81/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 19.3196 - val_loss: 12.2631\n",
      "Epoch 82/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 19.9998 - val_loss: 15.3585\n",
      "Epoch 83/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.3255 - val_loss: 13.7646\n",
      "Epoch 84/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.3344 - val_loss: 10.9562\n",
      "Epoch 85/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.2293 - val_loss: 6.5156\n",
      "Epoch 86/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.8983 - val_loss: 14.9286\n",
      "Epoch 87/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.9511 - val_loss: 12.0682\n",
      "Epoch 88/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 18.9306 - val_loss: 10.0157\n",
      "Epoch 89/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 15.6422 - val_loss: 6.1486\n",
      "Epoch 90/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 19.9805 - val_loss: 11.6972\n",
      "Epoch 91/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.3177 - val_loss: 6.2561\n",
      "Epoch 92/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.2721 - val_loss: 5.9093\n",
      "Epoch 93/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 18.0088 - val_loss: 12.4323\n",
      "Epoch 94/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.0717 - val_loss: 8.9527\n",
      "Epoch 95/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.8790 - val_loss: 9.3444\n",
      "Epoch 96/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 18.5547 - val_loss: 5.5420\n",
      "Epoch 97/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.5245 - val_loss: 5.3433\n",
      "Epoch 98/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.9804 - val_loss: 6.2344\n",
      "Epoch 99/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.4355 - val_loss: 9.1039\n",
      "Epoch 100/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.0196 - val_loss: 13.1417\n",
      "Epoch 101/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.1920 - val_loss: 10.1367\n",
      "Epoch 102/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.0930 - val_loss: 12.4502\n",
      "Epoch 103/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.7409 - val_loss: 6.0918\n",
      "Epoch 104/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.2883 - val_loss: 11.3026\n",
      "Epoch 105/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.0816 - val_loss: 6.6492\n",
      "Epoch 106/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.1513 - val_loss: 6.9565\n",
      "Epoch 107/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.6466 - val_loss: 8.2205\n",
      "Epoch 108/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.1450 - val_loss: 6.8799\n",
      "Epoch 109/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 19.7035 - val_loss: 8.2081\n",
      "Epoch 110/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.7031 - val_loss: 8.6975\n",
      "Epoch 111/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 15.7372 - val_loss: 11.1104\n",
      "Epoch 112/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 15.9097 - val_loss: 7.6814\n",
      "Epoch 113/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.1826 - val_loss: 8.3954\n",
      "Epoch 114/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 15.3248 - val_loss: 6.1091\n",
      "Epoch 115/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.2960 - val_loss: 7.0425\n",
      "Epoch 116/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.2809 - val_loss: 11.1123\n",
      "Epoch 117/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.6141 - val_loss: 11.9933\n",
      "Epoch 118/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.8429 - val_loss: 7.7711\n",
      "Epoch 119/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.0878 - val_loss: 7.6817\n",
      "Epoch 120/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 15.9729 - val_loss: 9.6060\n",
      "Epoch 121/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.5829 - val_loss: 6.3414\n",
      "Epoch 122/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.9322 - val_loss: 5.6437\n",
      "Epoch 123/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.1013 - val_loss: 4.8250\n",
      "Epoch 124/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.2306 - val_loss: 6.7798\n",
      "Epoch 125/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 19s 25ms/step - loss: 16.6700 - val_loss: 8.5147\n",
      "Epoch 126/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 15.9904 - val_loss: 9.1570\n",
      "Epoch 127/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.7788 - val_loss: 5.3726\n",
      "Epoch 128/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.5308 - val_loss: 8.4789\n",
      "Epoch 129/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.2642 - val_loss: 10.6526\n",
      "Epoch 130/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.4110 - val_loss: 10.7447\n",
      "Epoch 131/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.4375 - val_loss: 8.2729\n",
      "Epoch 132/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 15.8864 - val_loss: 11.7584\n",
      "Epoch 133/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.6237 - val_loss: 8.0502\n",
      "Epoch 134/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.1869 - val_loss: 17.3423\n",
      "Epoch 135/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.2366 - val_loss: 15.0519\n",
      "Epoch 136/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.5255 - val_loss: 6.9886\n",
      "Epoch 137/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 15.9855 - val_loss: 7.3559\n",
      "Epoch 138/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.8388 - val_loss: 8.5207\n",
      "Epoch 139/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.0393 - val_loss: 7.7048\n",
      "Epoch 140/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.4445 - val_loss: 9.5774\n",
      "Epoch 141/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.3285 - val_loss: 7.6006\n",
      "Epoch 142/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 15.9203 - val_loss: 12.2515\n",
      "Epoch 143/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.6648 - val_loss: 9.8529\n",
      "Epoch 144/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 18.2433 - val_loss: 9.3577\n",
      "Epoch 145/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 18.1445 - val_loss: 8.7910\n",
      "Epoch 146/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.4701 - val_loss: 11.2336\n",
      "Epoch 147/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 18.5106 - val_loss: 13.5100\n",
      "Epoch 148/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 15.6176 - val_loss: 17.5418\n",
      "Epoch 149/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.6816 - val_loss: 11.5777\n",
      "Epoch 150/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.3870 - val_loss: 8.4450\n",
      "Epoch 151/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.8907 - val_loss: 8.2615\n",
      "Epoch 152/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.7914 - val_loss: 6.6003\n",
      "Epoch 153/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.7972 - val_loss: 10.5332\n",
      "Epoch 154/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.8571 - val_loss: 6.2498\n",
      "Epoch 155/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 15.9857 - val_loss: 7.9608\n",
      "Epoch 156/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 15.1781 - val_loss: 10.8443\n",
      "Epoch 157/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 18.1285 - val_loss: 10.4250\n",
      "Epoch 158/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.0635 - val_loss: 14.9449\n",
      "Epoch 159/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 19.4450 - val_loss: 8.0907\n",
      "Epoch 160/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.1337 - val_loss: 9.3954\n",
      "Epoch 161/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.9234 - val_loss: 4.1913\n",
      "Epoch 162/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.8416 - val_loss: 6.6457\n",
      "Epoch 163/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.8576 - val_loss: 7.5032\n",
      "Epoch 164/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.4525 - val_loss: 4.5113\n",
      "Epoch 165/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 23.3385 - val_loss: 7.5192\n",
      "Epoch 166/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 19.5540 - val_loss: 6.8536\n",
      "Epoch 167/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.6681 - val_loss: 8.5464\n",
      "Epoch 168/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 19.3144 - val_loss: 6.5774\n",
      "Epoch 169/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.1391 - val_loss: 9.6631\n",
      "Epoch 170/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.8435 - val_loss: 7.5339\n",
      "Epoch 171/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 18.7256 - val_loss: 9.1987\n",
      "Epoch 172/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.5064 - val_loss: 9.9763\n",
      "Epoch 173/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.4598 - val_loss: 6.9516\n",
      "Epoch 174/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.1110 - val_loss: 6.9160\n",
      "Epoch 175/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 15.3265 - val_loss: 5.6682\n",
      "Epoch 176/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 19.5700 - val_loss: 7.7404\n",
      "Epoch 177/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.8659 - val_loss: 10.2877\n",
      "Epoch 178/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.0583 - val_loss: 7.8979\n",
      "Epoch 179/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 15.9175 - val_loss: 6.4358\n",
      "Epoch 180/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 18.8585 - val_loss: 5.7042\n",
      "Epoch 181/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.9081 - val_loss: 7.8366\n",
      "Epoch 182/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 15.6968 - val_loss: 8.0718\n",
      "Epoch 183/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 15.2862 - val_loss: 4.1102\n",
      "Epoch 184/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 15.1769 - val_loss: 10.0453\n",
      "Epoch 185/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.6167 - val_loss: 6.6401\n",
      "Epoch 186/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 15.4724 - val_loss: 10.2265\n",
      "Epoch 187/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.2520 - val_loss: 6.6006\n",
      "Epoch 188/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.5384 - val_loss: 6.8530\n",
      "Epoch 189/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.0302 - val_loss: 5.8693\n",
      "Epoch 190/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.5519 - val_loss: 9.3439\n",
      "Epoch 191/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 15.7243 - val_loss: 7.9108\n",
      "Epoch 192/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 15.7135 - val_loss: 6.9116\n",
      "Epoch 193/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 18.7221 - val_loss: 5.6068\n",
      "Epoch 194/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.8881 - val_loss: 13.4184\n",
      "Epoch 195/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.4032 - val_loss: 5.6342\n",
      "Epoch 196/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 15.5610 - val_loss: 6.2752\n",
      "Epoch 197/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 15.6377 - val_loss: 7.7675\n",
      "Epoch 198/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 16.2223 - val_loss: 10.3253\n",
      "Epoch 199/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 18.7765 - val_loss: 10.6509\n",
      "Epoch 200/200\n",
      "768/768 [==============================] - 19s 25ms/step - loss: 17.2172 - val_loss: 10.0607\n",
      "[INFO] predicting distances...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fddc5b8da664>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetlocale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLC_ALL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"en_US.UTF-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m print(\"[INFO] avg. house price: {}, std house price: {}\".format(\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"price\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrouping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \tlocale.currency(df[\"price\"].std(), grouping=True)))\n\u001b[1;32m    110\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] mean: {:.2f}%, std: {:.2f}%\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# %load cnn_regression-Copy1.py\n",
    "# USAGE\n",
    "# python cnn_regression.py --dataset Houses-dataset/Houses\\ Dataset/\n",
    "\n",
    "# import the necessary packages\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyimagesearch import models\n",
    "import numpy as np\n",
    "import argparse\n",
    "import locale\n",
    "import os\n",
    "import sys\n",
    "from matplotlib.image import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "IMG_WIDTH = 1400\n",
    "IMG_HEIGHT = 1400\n",
    "ROW_SLICE = slice(0, 1400)\n",
    "COL_SLICE = slice(1000, None)\n",
    "\n",
    "\n",
    "def cut_X(arr, reshape = None):\n",
    "    x_cut = arr[:,960:1300,600:]\n",
    "    if reshape:\n",
    "        if len(x_cut.shape)>3:\n",
    "            x_cut = x_cut[...,0]\n",
    "            x_cut_out = x_cut.reshape(x_cut.shape[0],x_cut.shape[1]*x_cut.shape[2])\n",
    "    else:\n",
    "        x_cut_out = x_cut\n",
    "    return x_cut_out\n",
    "\n",
    "\n",
    "#data_dir = \"/storage/yw18581/data/\"\n",
    "data_dir = \"/data/uob\"\n",
    "TRAIN_VAL_TEST_DIR = os.path.join(data_dir, \"train_validation_test\")\n",
    "\n",
    "N_EPOCHS=200\n",
    "\n",
    "CHECKPOINT_FOLDER_PATH = os.path.join(data_dir, 'trained_models')\n",
    "TASK_NAME = 'CNN_regression_pyimage_{}epochs'.format(N_EPOCHS)\n",
    "TASK_FOLDER_PATH = os.path.join(CHECKPOINT_FOLDER_PATH, TASK_NAME)\n",
    "\n",
    "if not os.path.exists(TASK_FOLDER_PATH):\n",
    "    os.makedirs(TASK_FOLDER_PATH)\n",
    "\n",
    "\n",
    "X_train = np.load(os.path.join(TRAIN_VAL_TEST_DIR,\"Xy_train_dist.npz\"))[\"y\"]\n",
    "X_val = np.load(os.path.join(TRAIN_VAL_TEST_DIR,\"Xy_val_dist.npz\"))[\"y\"]\n",
    "X_test = np.load(os.path.join(TRAIN_VAL_TEST_DIR,\"Xy_test_dist.npz\"))[\"y\"]\n",
    "\n",
    "y_train = np.load(os.path.join(TRAIN_VAL_TEST_DIR,\"Xy_train_dist.npz\"))[\"dist\"]\n",
    "y_val = np.load(os.path.join(TRAIN_VAL_TEST_DIR,\"Xy_val_dist.npz\"))[\"dist\"]\n",
    "y_test = np.load(os.path.join(TRAIN_VAL_TEST_DIR,\"Xy_test_dist.npz\"))[\"dist\"]\n",
    "\n",
    "X_train_cut = cut_X(X_train)\n",
    "X_val_cut = cut_X(X_val)\n",
    "X_test_cut = cut_X(X_test)\n",
    "\n",
    "\n",
    "# find the largest house price in the training set and use it to\n",
    "# scale our house prices to the range [0, 1] (will lead to better\n",
    "# training and convergence)\n",
    "maxDist = np.max(y_train)\n",
    "print(maxDist)\n",
    "trainY = y_train/maxDist\n",
    "valY = y_val/maxDist\n",
    "testY = y_test/maxDist\n",
    "\n",
    "# create our Convolutional Neural Network and then compile the model\n",
    "# using mean absolute percentage error as our loss, implying that we\n",
    "# seek to minimize the absolute percentage difference between our\n",
    "# price *predictions* and the *actual prices*\n",
    "\n",
    "_, width, height, depth,  = X_train_cut.shape\n",
    "\n",
    "model = models.create_cnn(height,width, depth, regress=True)\n",
    "opt = Adam(lr=1e-3, decay=1e-3 / N_EPOCHS)\n",
    "model.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt)\n",
    "model.summary()\n",
    "\n",
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "model.fit(X_train_cut, trainY, validation_data=(X_val_cut, valY),\n",
    "\tepochs=N_EPOCHS, batch_size=8, verbose=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] predicting distances...\n"
     ]
    }
   ],
   "source": [
    "# make predictions on the testing data\n",
    "print(\"[INFO] predicting distances...\")\n",
    "preds = model.predict(X_test_cut)\n",
    "\n",
    "# compute the difference between the *predicted* house prices and the\n",
    "# *actual* house prices, then compute the percentage difference and\n",
    "# the absolute percentage difference\n",
    "diff = preds.flatten() - testY\n",
    "percentDiff = (diff / testY) * 100\n",
    "absPercentDiff = np.abs(percentDiff)\n",
    "mean = np.mean(absPercentDiff)\n",
    "std = np.std(absPercentDiff)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.960592955661317"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168.8568395557665"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compute the mean and standard deviation of the absolute percentage\n",
    "# difference\n",
    "\n",
    "# finally, show some statistics on our model\n",
    "locale.setlocale(locale.LC_ALL, \"en_US.UTF-8\")\n",
    "print(\"[INFO] avg. house price: {}, std house price: {}\".format(\n",
    "\tlocale.currency(df[\"price\"].mean(), grouping=True),\n",
    "\tlocale.currency(df[\"price\"].std(), grouping=True)))\n",
    "print(\"[INFO] mean: {:.2f}%, std: {:.2f}%\".format(mean, std))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
